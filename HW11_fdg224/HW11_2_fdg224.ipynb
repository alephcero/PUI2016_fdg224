{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# HW 10 CLUSTERING BUSINESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# cluster time trends in NYC businesses: \n",
    "# DATA\n",
    "# Census Business data:\n",
    "## download census data for businesses by ZIP code. the data is here\n",
    "http://www.census.gov/econ/cbp/download/\n",
    "##  you can  download it with 3 terminal commands as follows: the data from 1993 through 2001 is different in the format of its path than the data after 2001 (that is why more than one for loop is needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import zipfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zbp93totals.zip\n",
      "zbp94totals.zip\n",
      "zbp95totals.zip\n",
      "zbp96totals.zip\n",
      "zbp97totals.zip\n",
      "zbp98totals.zip\n",
      "zbp99totals.zip\n",
      "zbp00totals.zip\n",
      "zbp01totals.zip\n",
      "zbp02totals.zip\n",
      "zbp03totals.zip\n",
      "zbp04totals.zip\n",
      "zbp05totals.zip\n",
      "zbp06totals.zip\n",
      "zbp07totals.zip\n",
      "zbp08totals.zip\n",
      "zbp09totals.zip\n",
      "zbp10totals.zip\n",
      "zbp11totals.zip\n",
      "zbp12totals.zip\n",
      "zbp13totals.zip\n",
      "zbp14totals.zip\n",
      "zbp15totals.zip\n"
     ]
    }
   ],
   "source": [
    "#!for ((y=93; y<=99; y+=1)); do wget ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp$y\\totals.zip; done\n",
    "for y in range(1993,2016):\n",
    "    filename = 'zbp'+str(y)[2:]+'totals.zip'\n",
    "\n",
    "    if y <= 2001:\n",
    "        os.system('wget ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/' + filename)\n",
    "    else: \n",
    "        os.system('wget ftp://ftp.census.gov/econ' + str(y) + '/CBP_CSV/' + filename)\n",
    "    print filename\n",
    "    os.system('mv '+filename + ' ' + os.getenv(\"PUIDATA\") + '/ecoCensus/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: \n",
    "to read in a zip file without unzipping it you can use the pandas and zipfile packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ZIPCODES\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/fedhere/PUI2016_fb55/master/HW11_fb55/'\n",
    "filename = 'nyc-zip-code-tabulation-areas-polygons.geojson'\n",
    "os.system('wget '+ url + filename)\n",
    "\n",
    "os.system('mv ' + filename + ' ' + os.getenv(\"PUIDATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipcodes = gpd.read_file(os.getenv(\"PUIDATA\") +'/' + filename)\n",
    "zipcodes = zipcodes.loc[:,['OBJECTID','PO_NAME','borough','geometry','postalCode']]\n",
    "zipcodes.postalCode = zipcodes.postalCode.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipcodes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(os.getenv(\"PUIDATA\") +'/ecoCensus/'):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#REMOVE THIS FILENAME AFTER\n",
    "years = range(1994,2000)\n",
    "mergeData = zipcodes.copy()\n",
    "for i in range(len(f)):\n",
    "    filename = f[i]\n",
    "    zf = zipfile.ZipFile(os.getenv(\"PUIDATA\") +'/ecoCensus/' + filename)\n",
    "    df = pd.read_csv(zf.open(filename.replace('.zip','.txt')))\n",
    "    #change this to upper case later\n",
    "    df = df.iloc[:,[0,6]]\n",
    "    df.columns = ['postalCode',str(years[i])]\n",
    "    mergeData = pd.merge(left=mergeData,right=df,on = 'postalCode',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing variables\n",
    "def normalizeCol(column):\n",
    "    return (column - column.mean())/column.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column = mergeData['1994']\n",
    "(column - column.mean())/column.std()\n",
    "for col in mergeData.columns[4:]:\n",
    "    mergeData[col] = (mergeData[col] - mergeData[col].mean())/mergeData[col].std()\n",
    "    print col\n",
    "    print mergeData[col].mean(), mergeData[col].std()\n",
    "    #print mergeData[col].isnull().sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.matrix(mergeData.iloc[:,4:])\n",
    "X = np.where(np.isnan(X),0,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxK = 10\n",
    "\n",
    "for n_clusters in range(2,maxK):\n",
    "    #run the clustering\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=123)\n",
    "    #assign labels of clusters\n",
    "    cluster_labels = km.fit_predict(X)\n",
    "    #calculate average for each cluster\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters ={},\".format(n_clusters)+\" the average silhouette_score is :{}\".format(silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elbow(data,K):\n",
    "#data is your input as numpy form\n",
    "#K is a list of number of clusters you would like to show.\n",
    "    # Run the KMeans model and save all the results for each number of clusters\n",
    "    KM = [KMeans(n_clusters=k).fit(data) for k in K]\n",
    "    \n",
    "    # Save the centroids for each model with a increasing k\n",
    "    centroids = [k.cluster_centers_ for k in KM]\n",
    "\n",
    "    # For each k, get the distance between the data with each center. \n",
    "    D_k = [cdist(data, cent, 'euclidean') for cent in centroids]\n",
    "    \n",
    "    # But we only need the distance to the nearest centroid since we only calculate dist(x,ci) for its own cluster.\n",
    "    globals()['dist'] = [np.min(D,axis=1) for D in D_k]\n",
    "    \n",
    "    # Calculate the Average SSE.\n",
    "    avgWithinSS = [sum(d)/data.shape[0] for d in dist]\n",
    "    \n",
    "    \n",
    "    # Total with-in sum of square plot. Another way to show the result.\n",
    "    wcss = [sum(d**2) for d in dist]\n",
    "    tss = sum(pdist(data)**2)/data.shape[0]\n",
    "    bss = tss-wcss\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(K, bss/tss*100, 'b*-')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Percentage of variance explained')\n",
    "    plt.title('Elbow for KMeans clustering')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elbow(X, range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#train the model.\n",
    "km2=KMeans(random_state=324,n_clusters=2)\n",
    "res2=km2.fit(X)\n",
    "km4=KMeans(random_state=324,n_clusters=4)\n",
    "res4=km4.fit(X)\n",
    "\n",
    "mergeData['k2'] = res2.labels_ \n",
    "mergeData['k4'] = res4.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print res2.cluster_centers_\n",
    "res2.cluster_centers_[0,0]\n",
    "res2.cluster_centers_[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mergeData['1994'])\n",
    "plt.plot(mergeData['1994'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8)) \n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "mergeData.plot(column = 'k2', alpha=1,linewidth=0.5,ax=ax1)\n",
    "mergeData.plot(column = 'k4', alpha=1,linewidth=0.5,ax=ax2)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1\n",
    "Map with NYC zipcodes colored accordingly to the cluster (with 2 and 4 clusters). We cluster based on the deviation from the mean in the amount of bussines in a given year. Therefore, zipcodes in the same cluster means that they are similar to each other in this terms. That means that every year they kept the same relative position in terms of amount of bussines. In a way, clusters are a proxy of consistency in time. If we use 2 clusters, we should come with one group of zipcodes with has, in a consisten way across time, higher values than the mean. In the other hand, the other we would have zipcodes consistently below the mean in terms of amount of bussiness. If we use more clusters, we could come up with zipcodes with high or low amount of bussines, but also some groups within them that are not so consisten, that with time they have grown economically or where affected by the crisis. Using 4 has the dissadvantage of the Central park as an outlier and a cluster by its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for y in years:\n",
    "    print mergeData.loc[mergeData.k2==1,[str(y)]].mean()\n",
    "    print mergeData.loc[mergeData.k2==0,[str(y)]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TASKS:\n",
    "    \n",
    "    1. get and prep your data.\n",
    "    2. cluster the NUMBER OF ESTABLISHMENTS time series with K-means in **a few** clusters (as discussed there is no real good, sound way to decide what a good number is here. try a few options, keeping in mind a few is more than a couple, but i recommand you stay within the single digit numbers)\n",
    "    3. plot the cluster centers (if you used K means those are the means of the clusters). you can plot for example the cluster centers overlayed on each time series (using the alpha channel to control the opacity in the plot may be helpful here).\n",
    "    4. Use another clustering algorithm (of your choice)\n",
    "    5. overlay your data on a NYC map: you can use shapefiles for the zip codes and different colors for different clusters\n",
    "    6. Compare the results of the 2 algorithms\n",
    "    7. attempt an interpretation. this is dangerous ground: clustering is an exploratory tool so you do not want to jump to conclusions because you see some clusters! but seeing structure in your data can inform your next moves as an investigator. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The map of the clusters may look something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(\"clustermap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you use hierarchical clustering and make a dandrogram it may look like this`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(\"dandrogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
